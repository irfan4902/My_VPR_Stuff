{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: numpy in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (1.26.3)\n",
      "Requirement already satisfied: seaborn in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: scikit-learn in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (1.4.2)\n",
      "Requirement already satisfied: ipykernel in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (6.29.3)\n",
      "Requirement already satisfied: tqdm in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: pillow in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (10.2.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (8.22.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: onnx in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (1.16.0)\n",
      "Requirement already satisfied: onnxruntime in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (1.17.3)\n",
      "Requirement already satisfied: quanto in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnx) (1.26.3)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnx) (5.26.1)\n",
      "Requirement already satisfied: coloredlogs in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: packaging in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: sympy in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: torch>=2.2.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from quanto) (2.3.0+cu118)\n",
      "Requirement already satisfied: ninja in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from quanto) (1.11.1.1)\n",
      "Requirement already satisfied: safetensors in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from quanto) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (4.11.0)\n",
      "Requirement already satisfied: networkx in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (11.8.86)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from torch>=2.2.0->quanto) (2.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/irfan/.conda/envs/bruh/lib/python3.11/site-packages (from jinja2->torch>=2.2.0->quanto) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install opencv-python numpy seaborn matplotlib scikit-learn ipykernel tqdm pillow\n",
    "%pip install onnx onnxruntime quanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import quanto\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "from datasets import dataset_utils\n",
    "from matching import matching\n",
    "from evaluation.metrics import createPR, recallAt100precision, recallAtK\n",
    "from datasets.load_dataset import GardensPointDataset, SFUDataset, StLuciaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GardensPointDataset().load()\n",
    "# SFUDataset().load()\n",
    "# StLuciaDataset().load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = \"calc.caffemodel.pt\"\n",
    "ITERATIONS = 100 # for testing average duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToYUVandEqualizeHist:\n",
    "    def __call__(self, img):\n",
    "        img_yuv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img_rgb = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        return Image.fromarray(img_rgb)\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        ConvertToYUVandEqualizeHist(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((120, 160), interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, name, folder, transform=None):\n",
    "        \n",
    "        self.name = os.path.basename(name)\n",
    "        self.folder = os.path.join(name, folder)\n",
    "        self.image_paths = dataset_utils.read_images_paths(self.folder, get_abs_path=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_path = self.image_paths[index]\n",
    "        img = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length: 385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3098, 0.4431, 0.6235,  ..., 0.0314, 0.0196, 0.0196],\n",
       "         [0.1882, 0.4471, 0.7020,  ..., 0.0471, 0.0353, 0.0353],\n",
       "         [0.1412, 0.4392, 0.6510,  ..., 0.0431, 0.0314, 0.0353],\n",
       "         ...,\n",
       "         [0.7882, 0.8157, 0.8314,  ..., 0.1529, 0.1176, 0.0824],\n",
       "         [0.7961, 0.8118, 0.8353,  ..., 0.1333, 0.0902, 0.0627],\n",
       "         [0.7843, 0.8000, 0.8196,  ..., 0.0980, 0.0588, 0.0431]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_db = CustomImageDataset(\"images/SFU\", \"dry\", preprocess)\n",
    "dataset_q = CustomImageDataset(\"images/SFU\", \"jan\", preprocess)\n",
    "\n",
    "print(\"Dataset Length:\", len(dataset_db))\n",
    "dataset_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 8\n",
    "db_dataloader = DataLoader(dataset_db, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "q_dataloader = DataLoader(dataset_q, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModelCompiled(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    @torch.compile\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfan/.conda/envs/bruh/lib/python3.11/site-packages/torch/onnx/_internal/jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "/home/irfan/.conda/envs/bruh/lib/python3.11/site-packages/torch/onnx/utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "/home/irfan/.conda/envs/bruh/lib/python3.11/site-packages/torch/onnx/utils.py:1208: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "example_input = torch.randn(1, 1, 120, 160)\n",
    "\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    calc,  # model\n",
    "    example_input,  # example input\n",
    "    \"calc_model.onnx\",  # output file name\n",
    "    input_names=[\"input\"],  # input names\n",
    "    output_names=[\"output\"],  # output names\n",
    "    dynamic_axes=dynamic_axes,  # dynamic axes\n",
    ")\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"calc_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/lrn1/Slice_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 5\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/lrn2/Slice_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 5\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'calc_model.onnx'\n",
    "model_quant = 'calc_model_quant_dynamic.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "\n",
    "# Load the dynamic quantized model\n",
    "ort_session_quant_dynamic = onnxruntime.InferenceSession(\"calc_model_quant_dynamic.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnxruntime.tools.symbolic_shape_infer import SymbolicShapeInference\n",
    "\n",
    "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
    "\n",
    "quant_pre_process('calc_model.onnx', 'calc_model_quant_static_prep.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 120, 160])\n",
      "torch.Size([285, 1, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "# calib_ds = db_tensor[:100] # first 100 for calibration - reserve for quantization\n",
    "# val_ds = db_tensor[100:] # last 100 for validation\n",
    "\n",
    "calib_ds = torch.stack([dataset_db[i] for i in range(100)])\n",
    "val_ds = torch.stack([dataset_db[i] for i in range(100, len(dataset_db))])\n",
    "\n",
    "print(calib_ds.shape)\n",
    "print(val_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization.calibrate import CalibrationDataReader\n",
    "\n",
    "class QuantizationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, torch_ds, batch_size, input_name):\n",
    "        self.torch_dl = torch.utils.data.DataLoader(torch_ds, batch_size=batch_size, shuffle=False)\n",
    "        self.input_name = input_name\n",
    "        self.datasize = len(self.torch_dl)\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "    def to_numpy(self, pt_tensor):\n",
    "        return pt_tensor.detach().cpu().numpy() if pt_tensor.requires_grad else pt_tensor.cpu().numpy()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.enum_data, None)\n",
    "        if batch is not None:\n",
    "\n",
    "            data = self.to_numpy(batch[0])\n",
    "            data = np.expand_dims(data, axis=0)  # Add a new dimension to the data\n",
    "            \n",
    "            return {self.input_name: data}\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "qdr = QuantizationDataReader(calib_ds, batch_size=64, input_name=ort_session.get_inputs()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\n",
      "WARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_static\n",
    "\n",
    "q_static_opts = {\"ActivationSymmetric\":False,\n",
    "                 \"WeightSymmetric\":True}\n",
    "# if torch.cuda.is_available():\n",
    "#     q_static_opts = {\"ActivationSymmetric\":True,\n",
    "#                   \"WeightSymmetric\":True}\n",
    "\n",
    "# q_static_opts = {\"ActivationSymmetric\":False, \"WeightSymmetric\":False}\n",
    "\n",
    "# check layer quantization support\n",
    "\n",
    "quantized_model = quantize_static(model_input='calc_model_quant_static_prep.onnx',\n",
    "                                               model_output='calc_model_quant_static.onnx',\n",
    "                                               calibration_data_reader=qdr,\n",
    "                                               extra_options=q_static_opts)\n",
    "\n",
    "# Load the static quantized model\n",
    "ort_session_quant_static = onnxruntime.InferenceSession('calc_model_quant_static.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization (Quanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n",
      "CalcModel(\n",
      "  (conv1): QConv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): QConv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): QConv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc_quanto = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc_quanto.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc_quanto)\n",
    "\n",
    "quanto.quantize(calc_quanto, weights=quanto.qint8, activations=quanto.qint8) # quantization is in place\n",
    "print(calc_quanto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): CalcModel(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu3): ReLU()\n",
      "    (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "    (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc_compiled = torch.compile(calc, mode='default')\n",
    "\n",
    "print(calc_compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(dataloader, model):\n",
    "    features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            output = model(batch)\n",
    "            features.append(output)\n",
    "\n",
    "    features = torch.cat(features, axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "calc.eval()\n",
    "\n",
    "# Process database tensor\n",
    "db_features = run_model(db_dataloader, calc)\n",
    "print(db_features.shape)\n",
    "\n",
    "# Process query tensor\n",
    "q_features = run_model(q_dataloader, calc)\n",
    "print(q_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_onnx_model(dataloader, ort_session, input_name):\n",
    "    features_quant_dynamic = []\n",
    "\n",
    "    for inputs in dataloader:\n",
    "        # Convert the tensor to numpy\n",
    "        inputs = inputs.detach().cpu().numpy()\n",
    "\n",
    "        # Create the input dictionary\n",
    "        ort_input = {input_name: inputs}\n",
    "\n",
    "        # Run the model\n",
    "        ort_output = ort_session.run(None, ort_input)\n",
    "\n",
    "        # Append the output to the list\n",
    "        features_quant_dynamic.append(ort_output[0])\n",
    "\n",
    "    features_quant_dynamic = torch.from_numpy(np.concatenate(features_quant_dynamic, axis=0))\n",
    "    return features_quant_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model = onnx.load(\"calc_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session = onnxruntime.InferenceSession(\"calc_model.onnx\")\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "# Process database images\n",
    "db_features_onnx = run_onnx_model(db_dataloader, ort_session, input_name)\n",
    "print(db_features_onnx.shape)\n",
    "\n",
    "# Process query images\n",
    "q_features_onnx = run_onnx_model(q_dataloader, ort_session, input_name)\n",
    "print(q_features_onnx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model_quant_dynamic = onnx.load(\"calc_model_quant_dynamic.onnx\")\n",
    "onnx.checker.check_model(onnx_model_quant_dynamic)\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session_quant_dynamic = onnxruntime.InferenceSession(\"calc_model_quant_dynamic.onnx\")\n",
    "\n",
    "input_name = ort_session_quant_dynamic.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "# Process database images\n",
    "db_features_quant_dynamic = run_onnx_model(db_dataloader, ort_session_quant_dynamic, input_name)\n",
    "print(db_features_quant_dynamic.shape)\n",
    "\n",
    "# Process query images\n",
    "q_features_quant_dynamic = run_onnx_model(q_dataloader, ort_session_quant_dynamic, input_name)\n",
    "print(q_features_quant_dynamic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model_quant_static = onnx.load(\"calc_model_quant_static.onnx\")\n",
    "onnx.checker.check_model(onnx_model_quant_static)\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session_quant_static = onnxruntime.InferenceSession(\"calc_model_quant_static.onnx\")\n",
    "\n",
    "input_name = ort_session_quant_static.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "# Process database images\n",
    "db_features_quant_static = run_onnx_model(db_dataloader, ort_session_quant_static, input_name)\n",
    "print(db_features_quant_static.shape)\n",
    "\n",
    "# Process query images\n",
    "q_features_quant_static = run_onnx_model(q_dataloader, ort_session_quant_static, input_name)\n",
    "print(q_features_quant_static.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization (Quanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "calc_quanto.eval()\n",
    "\n",
    "# Process database tensor\n",
    "db_features_quanto = run_model(db_dataloader, calc)\n",
    "print(db_features_quanto.shape)\n",
    "\n",
    "# Process query tensor\n",
    "q_features_quanto = run_model(q_dataloader, calc)\n",
    "print(db_features_quanto.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "calc_compiled.eval()\n",
    "\n",
    "# Process database tensor\n",
    "db_features_torch_comp = run_model(db_dataloader, calc)\n",
    "print(db_features_torch_comp.shape)\n",
    "\n",
    "# Process query tensor\n",
    "q_features_torch_comp = run_model(q_dataloader, calc)\n",
    "print(q_features_torch_comp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(dataloader, model, iterations, desc):\n",
    "    times = []\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=desc):\n",
    "        start_time = time.time()\n",
    "\n",
    "        run_model(dataloader, model)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    avg_time = sum(times) / len(times)\n",
    "\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time_onnx(dataloader, ort_session, input_name, iterations, desc):\n",
    "    times = []\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=desc):\n",
    "        start_time = time.time()\n",
    "\n",
    "        run_onnx_model(dataloader, ort_session, input_name)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    avg_time = sum(times) / len(times)\n",
    "\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing database dataset: 100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Average Time: 0.845102665424347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [01:25<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Average Time: 0.8495185351371766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_avg_time = measure_time(db_dataloader, calc, ITERATIONS, \"Processing database dataset\")\n",
    "print(f\"Database Average Time: {db_avg_time}\")\n",
    "\n",
    "q_avg_time = measure_time(q_dataloader, calc, ITERATIONS, \"Processing query dataset\")\n",
    "print(f\"Query Average Time: {q_avg_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantization (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing database dataset: 100%|██████████| 100/100 [01:15<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Average Time: 0.7500852632522583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [01:16<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Average Time: 0.76621089220047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_avg_time_quant_dynamic = measure_time_onnx(db_dataloader, ort_session_quant_dynamic, input_name, ITERATIONS, \"Processing database dataset\")\n",
    "print(f\"Database Average Time: {db_avg_time_quant_dynamic}\")\n",
    "\n",
    "q_avg_time_quant_dynamic = measure_time_onnx(q_dataloader, ort_session_quant_dynamic, input_name, ITERATIONS, \"Processing query dataset\")\n",
    "print(f\"Query Average Time: {q_avg_time_quant_dynamic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing database dataset: 100%|██████████| 100/100 [01:14<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Average Time: 0.7493634605407715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [01:14<00:00,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Average Time: 0.741964647769928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_avg_time_quant_static = measure_time_onnx(db_dataloader, ort_session_quant_static, input_name, ITERATIONS, \"Processing database dataset\")\n",
    "print(f\"Database Average Time: {db_avg_time_quant_static}\")\n",
    "\n",
    "q_avg_time_quant_static = measure_time_onnx(q_dataloader, ort_session_quant_static, input_name, ITERATIONS, \"Processing query dataset\")\n",
    "print(f\"Query Average Time: {q_avg_time_quant_static}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization (Quanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing database dataset: 100%|██████████| 100/100 [01:50<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Average Time: 1.1022711992263794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [01:49<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Average Time: 1.0992321348190308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_avg_time_quanto = measure_time(db_dataloader, calc_quanto, ITERATIONS, \"Processing database dataset\")\n",
    "print(f\"Database Average Time: {db_avg_time_quanto}\")\n",
    "\n",
    "q_avg_time_quanto = measure_time(q_dataloader, calc_quanto, ITERATIONS, \"Processing query dataset\")\n",
    "print(f\"Query Average Time: {q_avg_time_quanto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing database dataset: 100%|██████████| 100/100 [01:13<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Average Time: 0.7305069255828858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Average Time: 0.6960044693946839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db_avg_time_comp = measure_time(db_dataloader, calc_compiled, ITERATIONS, \"Processing database dataset\")\n",
    "print(f\"Database Average Time: {db_avg_time_comp}\")\n",
    "\n",
    "q_avg_time_comp = measure_time(q_dataloader, calc_compiled, ITERATIONS, \"Processing query dataset\")\n",
    "print(f\"Query Average Time: {q_avg_time_comp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vprtutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
