{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from matching import matching\n",
    "from evaluation.metrics import createPR, recallAt100precision, recallAtK\n",
    "from datasets.load_dataset import GardensPointDataset, SFUDataset, StLuciaDataset\n",
    "\n",
    "# conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\n",
    "# conda install onnx onnxruntime\n",
    "# pip install torch torchvision numpy opencv-python seaborn matplotlib scikit-learn pillow onnxscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Load dataset SFU dry--jan\n"
     ]
    }
   ],
   "source": [
    "imgs_db, imgs_q, GThard, GTsoft = SFUDataset().load()\n",
    "# imgs_db, imgs_q, GThard, GTsoft = GardensPointDataset().load()\n",
    "# imgs_db, imgs_q, GThard, GTsoft = StLuciaDataset().load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = \"calc.caffemodel.pt\"\n",
    "ITERATIONS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToYUVandEqualizeHist:\n",
    "    def __call__(self, img):\n",
    "        img_yuv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img_rgb = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        return Image.fromarray(img_rgb)\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        ConvertToYUVandEqualizeHist(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((120, 160), interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 1, 120, 160])\n",
      "tensor([[[[0.3098, 0.4431, 0.6235,  ..., 0.0314, 0.0196, 0.0196],\n",
      "          [0.1882, 0.4471, 0.7020,  ..., 0.0471, 0.0353, 0.0353],\n",
      "          [0.1412, 0.4392, 0.6510,  ..., 0.0431, 0.0314, 0.0353],\n",
      "          ...,\n",
      "          [0.7882, 0.8157, 0.8314,  ..., 0.1529, 0.1176, 0.0824],\n",
      "          [0.7961, 0.8118, 0.8353,  ..., 0.1333, 0.0902, 0.0627],\n",
      "          [0.7843, 0.8000, 0.8196,  ..., 0.0980, 0.0588, 0.0431]]],\n",
      "\n",
      "\n",
      "        [[[0.6275, 0.6039, 0.5804,  ..., 0.8118, 0.8000, 0.7569],\n",
      "          [0.5216, 0.5333, 0.5176,  ..., 0.8157, 0.7922, 0.7333],\n",
      "          [0.3922, 0.4863, 0.4706,  ..., 0.8078, 0.7765, 0.7294],\n",
      "          ...,\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.2667, 0.1843, 0.1373],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.2392, 0.1373, 0.1098],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.1490, 0.0980, 0.0588]]],\n",
      "\n",
      "\n",
      "        [[[0.0902, 0.2039, 0.3294,  ..., 0.8392, 0.8980, 0.9451],\n",
      "          [0.1529, 0.2510, 0.3490,  ..., 0.8627, 0.8706, 0.9412],\n",
      "          [0.1490, 0.2314, 0.3059,  ..., 0.9255, 0.8627, 0.9059],\n",
      "          ...,\n",
      "          [0.7333, 0.7137, 0.7608,  ..., 0.1725, 0.1529, 0.1451],\n",
      "          [0.6471, 0.6549, 0.6745,  ..., 0.1686, 0.1373, 0.1294],\n",
      "          [0.6275, 0.6196, 0.6314,  ..., 0.1412, 0.1255, 0.1176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9647, 0.9804, 0.9882,  ..., 0.8667, 0.9529, 0.9529],\n",
      "          [0.9922, 0.9882, 0.9765,  ..., 0.7922, 0.8902, 0.9216],\n",
      "          [0.9843, 0.9804, 0.9569,  ..., 0.6980, 0.7804, 0.8353],\n",
      "          ...,\n",
      "          [0.0235, 0.0275, 0.0353,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.0235, 0.0275, 0.0353,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.0196, 0.0235, 0.0314,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 0.0157, 0.0392, 0.0667],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.0157, 0.0353, 0.0824],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 0.0196, 0.0235, 0.0549],\n",
      "          ...,\n",
      "          [0.0824, 0.1451, 0.1765,  ..., 0.7176, 0.7176, 0.7216],\n",
      "          [0.0824, 0.1333, 0.1569,  ..., 0.7098, 0.6275, 0.5412],\n",
      "          [0.0588, 0.0706, 0.0863,  ..., 0.7412, 0.5176, 0.2902]]],\n",
      "\n",
      "\n",
      "        [[[0.3647, 0.4235, 0.5098,  ..., 0.4078, 0.0275, 0.0275],\n",
      "          [0.4706, 0.4824, 0.5843,  ..., 0.4863, 0.0902, 0.0314],\n",
      "          [0.5176, 0.5373, 0.5725,  ..., 0.5529, 0.1412, 0.0275],\n",
      "          ...,\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0392, 0.0275, 0.0118],\n",
      "          [0.0078, 0.0039, 0.0039,  ..., 0.0235, 0.0157, 0.0078],\n",
      "          [0.0078, 0.0039, 0.0078,  ..., 0.0157, 0.0118, 0.0039]]]])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess query images\n",
    "\n",
    "query_matrix = []\n",
    "\n",
    "for image in imgs_db:\n",
    "    preprocessed_image = preprocess(image)\n",
    "    query_matrix.append(preprocessed_image)\n",
    "\n",
    "query_matrix = np.stack(query_matrix, axis=0)\n",
    "\n",
    "# Convert numpy array to a tensor\n",
    "query_tensor = torch.from_numpy(query_matrix)\n",
    "\n",
    "print(query_tensor.shape)\n",
    "print(query_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 1, 120, 160])\n",
      "tensor([[[[0.5725, 0.6667, 0.6784,  ..., 0.3098, 0.1569, 0.0941],\n",
      "          [0.2157, 0.5686, 0.7490,  ..., 0.2588, 0.1569, 0.0941],\n",
      "          [0.0667, 0.1804, 0.6667,  ..., 0.2235, 0.1569, 0.1059],\n",
      "          ...,\n",
      "          [0.2980, 0.3529, 0.4314,  ..., 0.8196, 0.7961, 0.7725],\n",
      "          [0.1725, 0.2863, 0.4196,  ..., 0.8196, 0.7882, 0.7490],\n",
      "          [0.1725, 0.2745, 0.3765,  ..., 0.8118, 0.7569, 0.6824]]],\n",
      "\n",
      "\n",
      "        [[[0.8627, 0.9451, 0.9373,  ..., 0.9647, 0.8980, 0.8275],\n",
      "          [0.8980, 0.9059, 0.9451,  ..., 0.9804, 0.9333, 0.8824],\n",
      "          [0.4314, 0.6039, 0.9176,  ..., 0.9804, 0.9529, 0.9137],\n",
      "          ...,\n",
      "          [0.3137, 0.3922, 0.4784,  ..., 0.5451, 0.5961, 0.6118],\n",
      "          [0.2667, 0.3294, 0.3804,  ..., 0.5137, 0.5255, 0.5529],\n",
      "          [0.1922, 0.2588, 0.3098,  ..., 0.5020, 0.4941, 0.5059]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0000, 0.0039,  ..., 0.9765, 0.9373, 0.7765],\n",
      "          [0.0039, 0.0039, 0.0078,  ..., 0.9686, 0.9569, 0.8667],\n",
      "          [0.0000, 0.0039, 0.0196,  ..., 0.9804, 0.9686, 0.9412],\n",
      "          ...,\n",
      "          [0.5608, 0.5765, 0.5922,  ..., 0.5922, 0.5686, 0.5451],\n",
      "          [0.5529, 0.5647, 0.5843,  ..., 0.5882, 0.5569, 0.5255],\n",
      "          [0.5412, 0.5529, 0.5725,  ..., 0.6000, 0.5647, 0.5333]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0000, 0.0000,  ..., 0.3490, 0.5059, 0.6824],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3725, 0.4196, 0.5137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3529, 0.3490, 0.4784],\n",
      "          ...,\n",
      "          [0.0431, 0.0588, 0.0745,  ..., 0.2039, 0.1608, 0.1059],\n",
      "          [0.0392, 0.0471, 0.0549,  ..., 0.1647, 0.1412, 0.1098],\n",
      "          [0.0275, 0.0353, 0.0392,  ..., 0.1412, 0.1176, 0.0941]]],\n",
      "\n",
      "\n",
      "        [[[0.0392, 0.0353, 0.0431,  ..., 0.6549, 0.4314, 0.3098],\n",
      "          [0.0549, 0.0824, 0.0980,  ..., 0.9176, 0.7176, 0.3137],\n",
      "          [0.1490, 0.1843, 0.1608,  ..., 0.9529, 0.9176, 0.4941],\n",
      "          ...,\n",
      "          [0.1333, 0.1922, 0.2392,  ..., 0.3333, 0.4980, 0.5412],\n",
      "          [0.1255, 0.1882, 0.2314,  ..., 0.3961, 0.5176, 0.5255],\n",
      "          [0.1216, 0.1608, 0.2000,  ..., 0.4118, 0.4627, 0.4314]]],\n",
      "\n",
      "\n",
      "        [[[0.7020, 0.6510, 0.1412,  ..., 0.8941, 0.9137, 0.9216],\n",
      "          [0.2549, 0.3490, 0.1216,  ..., 0.8980, 0.9255, 0.9255],\n",
      "          [0.0000, 0.0000, 0.0588,  ..., 0.8824, 0.9059, 0.9176],\n",
      "          ...,\n",
      "          [0.0706, 0.0706, 0.0667,  ..., 0.2627, 0.2824, 0.1843],\n",
      "          [0.0392, 0.0431, 0.0471,  ..., 0.2196, 0.2000, 0.1176],\n",
      "          [0.0196, 0.0235, 0.0314,  ..., 0.1412, 0.1020, 0.0549]]]])\n"
     ]
    }
   ],
   "source": [
    "# Preprocess map images\n",
    "\n",
    "map_matrix = []\n",
    "\n",
    "for image in imgs_q:\n",
    "    preprocessed_image = preprocess(image)\n",
    "    map_matrix.append(preprocessed_image)\n",
    "\n",
    "map_matrix = np.stack(map_matrix, axis=0)\n",
    "\n",
    "# Convert numpy array to a tensor\n",
    "map_tensor = torch.from_numpy(map_matrix)\n",
    "\n",
    "print(map_tensor.shape)\n",
    "print(map_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized Model - Pytorch doesn't work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantized_model = torch.quantization.quantize_dynamic(\n",
    "#     calc,\n",
    "#     {nn.Conv2d, nn.MaxPool2d, nn.LocalResponseNorm},\n",
    "#     dtype=torch.qint8\n",
    "# )\n",
    "\n",
    "# print(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
      "  (1): CalcModel(\n",
      "    (conv1): QuantizedConvReLU2d(1, 64, kernel_size=(5, 5), stride=(2, 2), scale=0.009876943193376064, zero_point=0, padding=(4, 4))\n",
      "    (relu1): Identity()\n",
      "    (conv2): QuantizedConvReLU2d(64, 128, kernel_size=(4, 4), stride=(1, 1), scale=0.00443233922123909, zero_point=0, padding=(2, 2))\n",
      "    (relu2): Identity()\n",
      "    (conv3): QuantizedConvReLU2d(128, 4, kernel_size=(3, 3), stride=(1, 1), scale=0.0008810117724351585, zero_point=0)\n",
      "    (relu3): Identity()\n",
      "    (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "    (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  )\n",
      "  (2): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.quantization\n",
    "import copy\n",
    "\n",
    "quantized_model = CalcModel()\n",
    "quantized_model.eval()\n",
    "\n",
    "backend = \"x86\"\n",
    "# for raspberry pi should be set to \"qnnpack\"\n",
    "# try onnx quantization\n",
    "\n",
    "## EAGER MODE\n",
    "\n",
    "torch.quantization.fuse_modules(quantized_model, [['conv1', 'relu1'], ['conv2', 'relu2'], ['conv3', 'relu3']], inplace=True)\n",
    "\n",
    "quantized_model = nn.Sequential(torch.quantization.QuantStub(), \n",
    "                  quantized_model, \n",
    "                  torch.quantization.DeQuantStub())\n",
    "\n",
    "# Prepare\n",
    "quantized_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare(quantized_model, inplace=True)\n",
    "\n",
    "# Calibrate\n",
    "with torch.inference_mode():\n",
    "  for i in query_tensor[:100]: # idk if this is the right way to do this\n",
    "    quantized_model(i)\n",
    "\n",
    "# Convert\n",
    "torch.quantization.convert(quantized_model, inplace=True)\n",
    "\n",
    "# Check\n",
    "print(quantized_model) # 1 byte instead of 4 bytes for FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## FX GRAPH\n",
    "# from torch.quantization import quantize_fx\n",
    "\n",
    "# m = copy.deepcopy(calc)\n",
    "# m.eval()\n",
    "\n",
    "# qconfig_dict = {\"\": torch.quantization.get_default_qconfig(backend)}\n",
    "\n",
    "# # Prepare\n",
    "# example_inputs = (torch.rand(1, 1, 120, 160))\n",
    "\n",
    "# model_prepared = quantize_fx.prepare_fx(m, qconfig_dict, example_inputs)\n",
    "\n",
    "# # Calibrate\n",
    "# with torch.inference_mode():\n",
    "#   for i in query_tensor[:100]:\n",
    "#     model_prepared(i)\n",
    "\n",
    "# # Quantize\n",
    "# model_quantized = quantize_fx.convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = torch.randn(1, 1, 120, 160)\n",
    "\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    calc,  # model\n",
    "    example_input,  # example input\n",
    "    \"calc_model.onnx\",  # output file name\n",
    "    input_names=[\"input\"],  # input names\n",
    "    output_names=[\"output\"],  # output names\n",
    "    dynamic_axes=dynamic_axes,  # dynamic axes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "# Instantiate the Model\n",
    "calc_cuda = CalcModel().half().cuda()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc_cuda.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc_cuda.load_state_dict(my_new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 1, 120, 160])\n",
      "torch.Size([385, 1, 120, 160])\n",
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "query_tensor = torch.from_numpy(query_matrix)\n",
    "map_tensor = torch.from_numpy(map_matrix)\n",
    "\n",
    "print(query_tensor.shape)\n",
    "print(map_tensor.shape)\n",
    "\n",
    "query_tensor = query_tensor.view(-1, 1, 120, 160)\n",
    "map_tensor = map_tensor.view(-1, 1, 120, 160)\n",
    "\n",
    "# Pass the tensors through the model\n",
    "\n",
    "query_features = calc(query_tensor)\n",
    "map_features = calc(map_tensor)\n",
    "\n",
    "print(query_features.shape)\n",
    "print(map_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::mul.out' with arguments from the 'QuantizedCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::mul.out' is only available for these backends: [CPU, CUDA, Meta, MkldnnCPU, SparseCPU, SparseCUDA, SparseCsrCPU, SparseCsrCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCPU.cpp:31357 [kernel]\nCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCUDA.cpp:44411 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nMkldnnCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterMkldnnCPU.cpp:515 [kernel]\nSparseCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCPU.cpp:1387 [kernel]\nSparseCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCUDA.cpp:1573 [kernel]\nSparseCsrCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCsrCPU.cpp:1135 [kernel]\nSparseCsrCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCsrCUDA.cpp:1276 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterFunctionalization_0.cpp:21977 [kernel]\nNamed: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\ADInplaceOrViewType_0.cpp:4832 [kernel]\nAutogradOther: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradHIP: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradXLA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMPS: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradIPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradXPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradHPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradVE: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradLazy: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMTIA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse1: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse2: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse3: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\TraceType_0.cpp:16968 [kernel]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m quan_query_features \u001b[38;5;241m=\u001b[39m \u001b[43mquantized_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m quan_map_features \u001b[38;5;241m=\u001b[39m quantized_model(map_tensor)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(quan_query_features\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 20\u001b[0m, in \u001b[0;36mCalcModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n\u001b[1;32m---> 20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlrn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[0;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:58\u001b[0m, in \u001b[0;36mLocalResponseNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_response_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\torch\\nn\\functional.py:2583\u001b[0m, in \u001b[0;36mlocal_response_norm\u001b[1;34m(input, size, alpha, beta, k)\u001b[0m\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m-> 2583\u001b[0m div \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m   2585\u001b[0m     div \u001b[38;5;241m=\u001b[39m div\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'aten::mul.out' with arguments from the 'QuantizedCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::mul.out' is only available for these backends: [CPU, CUDA, Meta, MkldnnCPU, SparseCPU, SparseCUDA, SparseCsrCPU, SparseCsrCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCPU.cpp:31357 [kernel]\nCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCUDA.cpp:44411 [kernel]\nMeta: registered at /dev/null:488 [kernel]\nMkldnnCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterMkldnnCPU.cpp:515 [kernel]\nSparseCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCPU.cpp:1387 [kernel]\nSparseCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCUDA.cpp:1573 [kernel]\nSparseCsrCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCsrCPU.cpp:1135 [kernel]\nSparseCsrCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterSparseCsrCUDA.cpp:1276 [kernel]\nBackendSelect: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:498 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterFunctionalization_0.cpp:21977 [kernel]\nNamed: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:11 [kernel]\nConjugate: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\ADInplaceOrViewType_0.cpp:4832 [kernel]\nAutogradOther: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradHIP: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradXLA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMPS: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradIPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradXPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradHPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradVE: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradLazy: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMTIA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse1: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse2: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradPrivateUse3: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nAutogradNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:19039 [autograd kernel]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\TraceType_0.cpp:16968 [kernel]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:720 [backend fallback]\nBatchedNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:746 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:203 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:494 [backend fallback]\nPreDispatch: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "quan_query_features = quantized_model(query_tensor)\n",
    "quan_map_features = quantized_model(map_tensor)\n",
    "\n",
    "print(quan_query_features.shape)\n",
    "print(quan_map_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pytorch tensors to numpy arrays\n",
    "# query_features_np = query_features.detach().numpy()\n",
    "# map_features_np = map_features.detach().numpy()\n",
    "\n",
    "# similarity_matrix = cosine_similarity(query_features_np, map_features_np)\n",
    "\n",
    "# print(similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# sns.heatmap(similarity_matrix, cmap='viridis')\n",
    "# plt.title('Similarity matrix')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # best matching per query in S for single-best-match VPR\n",
    "# M1 = matching.best_match_per_query(similarity_matrix)\n",
    "\n",
    "# # find matches with S>=thresh using an auto-tuned threshold for multi-match VPR\n",
    "# M2 = matching.thresholding(similarity_matrix, 'auto')\n",
    "\n",
    "# TP = np.argwhere(M2 & GThard)  # true positives\n",
    "# FP = np.argwhere(M2 & ~GTsoft)  # false positives\n",
    "\n",
    "# # show M's\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(121)\n",
    "# ax1.imshow(M1)\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title('Best match per query')\n",
    "# ax2 = fig.add_subplot(122)\n",
    "# ax2.imshow(M2)\n",
    "# ax2.axis('off')\n",
    "# ax2.set_title('Thresholding S>=thresh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model = onnx.load(\"calc_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tensors to numpy arrays\n",
    "query_numpy = query_tensor.detach().cpu().numpy()\n",
    "map_numpy = map_tensor.detach().cpu().numpy()\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"calc_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input name from the model\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "# Ensure the inputs are numpy arrays\n",
    "query_numpy = np.array(query_numpy)\n",
    "map_numpy = np.array(map_numpy)\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_query_input = {input_name: query_numpy}\n",
    "\n",
    "# Run the model\n",
    "ort_query_output = ort_session.run(None, ort_query_input)\n",
    "\n",
    "# Convert the output to a numpy array and print its shape\n",
    "ort_query_output = np.array(ort_query_output)\n",
    "print(ort_query_output.shape)\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_map_input = {input_name: map_numpy}\n",
    "\n",
    "# Run the model\n",
    "ort_map_output = ort_session.run(None, ort_map_input)\n",
    "\n",
    "# Convert the output to a numpy array and print it\n",
    "ort_map_output = np.array(ort_map_output)\n",
    "print(ort_map_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_query_output = np.squeeze(ort_query_output)\n",
    "print(ort_query_output.shape)\n",
    "ort_map_output = np.squeeze(ort_map_output)\n",
    "print(ort_map_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the tensors through the model\n",
    "\n",
    "query_features = calc_cuda(query_tensor.half().cuda())\n",
    "map_features = calc_cuda(map_tensor.half().cuda())\n",
    "\n",
    "query_features_cpu = query_features.detach().cpu()\n",
    "map_features_cpu = map_features.detach().cpu()\n",
    "\n",
    "print(query_features_cpu.shape)\n",
    "print(map_features_cpu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time for query tensor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    output = calc(query_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "query_duration_calc = end_time - start_time\n",
    "query_avg_duration_calc = query_duration_calc / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {query_duration_calc} seconds\")\n",
    "print(f\"Average time taken: {query_avg_duration_calc} seconds\")\n",
    "\n",
    "# Average time for map tensor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    with torch.no_grad():\n",
    "        output = calc(map_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "map_duration_calc = end_time - start_time\n",
    "map_avg_duration_calc = map_duration_calc / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {map_duration_calc} seconds\")\n",
    "print(f\"Average time taken: {map_avg_duration_calc} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time for query tensor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    output = quantized_model(query_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "query_duration_calc = end_time - start_time\n",
    "query_avg_duration_calc = query_duration_calc / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {query_duration_calc} seconds\")\n",
    "print(f\"Average time taken: {query_avg_duration_calc} seconds\")\n",
    "\n",
    "# Average time for map tensor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    with torch.no_grad():\n",
    "        output = quantized_model(map_tensor)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "map_duration_calc = end_time - start_time\n",
    "map_avg_duration_calc = map_duration_calc / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {map_duration_calc} seconds\")\n",
    "print(f\"Average time taken: {map_avg_duration_calc} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average time for query tensor\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "ort_inputs = {input_name: query_numpy}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "query_duration_onnx = end_time - start_time\n",
    "query_avg_duration_onnx = query_duration_onnx / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {query_duration_onnx} seconds\")\n",
    "print(f\"Average time taken: {query_avg_duration_onnx} seconds\")\n",
    "\n",
    "# Average time for map tensor\n",
    "\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "ort_inputs = {input_name: map_numpy}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "map_duration_onnx = end_time - start_time\n",
    "map_avg_duration_onnx = map_duration_onnx / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {map_duration_onnx} seconds\")\n",
    "print(f\"Average time taken: {map_avg_duration_onnx} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    output = calc_cuda(query_tensor.half().cuda())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "query_duration_cuda = end_time - start_time\n",
    "query_avg_duration_cuda = query_duration_cuda / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {query_duration_cuda} seconds\")\n",
    "print(f\"Average time taken: {query_avg_duration_cuda} seconds\")\n",
    "\n",
    "# Average time for map tensor\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(ITERATIONS):\n",
    "    output = calc_cuda(map_tensor.half().cuda())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "map_duration_cuda = end_time - start_time\n",
    "map_avg_duration_cuda = map_duration_cuda / ITERATIONS\n",
    "\n",
    "print(f\"Time taken: {map_duration_cuda} seconds\")\n",
    "print(f\"Average time taken: {map_avg_duration_cuda} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables\n",
    "models = ['Normal', 'ONNX', 'CUDA']\n",
    "durations = [query_duration_calc, map_duration_onnx, map_duration_cuda]\n",
    "avg_durations = [query_avg_duration_calc, map_avg_duration_onnx, map_avg_duration_cuda]\n",
    "\n",
    "# Plot duration bar chart\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.bar(models, durations)\n",
    "plt.title('Duration')\n",
    "plt.ylabel('Duration')\n",
    "plt.show()\n",
    "\n",
    "# Plot average duration bar chart\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.bar(models, avg_durations)\n",
    "plt.title('Average Duration')\n",
    "plt.ylabel('Average Duration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision-recall curve\n",
    "P, R = createPR(similarity_matrix, GThard, GTsoft, matching='multi', n_thresh=100)\n",
    "plt.figure()\n",
    "plt.plot(R, P)\n",
    "plt.xlim(0, 1), plt.ylim(0, 1.01)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Result on GardensPoint day_right--night_right')\n",
    "plt.grid('on')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vprtutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
