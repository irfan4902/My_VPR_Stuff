{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import quanto\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "from datasets import dataset_utils\n",
    "from matching import matching\n",
    "from evaluation.metrics import createPR, recallAt100precision, recallAtK\n",
    "from datasets.load_dataset import GardensPointDataset, SFUDataset, StLuciaDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = \"calc.caffemodel.pt\"\n",
    "ITERATIONS = 100 # for testing average duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToYUVandEqualizeHist:\n",
    "    def __call__(self, img):\n",
    "        img_yuv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img_rgb = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        return Image.fromarray(img_rgb)\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        ConvertToYUVandEqualizeHist(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((120, 160), interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, name, folder, transform=None):\n",
    "        \n",
    "        self.name = os.path.basename(name)\n",
    "        self.folder = os.path.join(name, folder)\n",
    "        self.image_paths = dataset_utils.read_images_paths(self.folder, get_abs_path=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_path = self.image_paths[index]\n",
    "        img = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length: 385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3098, 0.4431, 0.6235,  ..., 0.0314, 0.0196, 0.0196],\n",
       "         [0.1882, 0.4471, 0.7020,  ..., 0.0471, 0.0353, 0.0353],\n",
       "         [0.1412, 0.4392, 0.6510,  ..., 0.0431, 0.0314, 0.0353],\n",
       "         ...,\n",
       "         [0.7882, 0.8157, 0.8314,  ..., 0.1529, 0.1176, 0.0824],\n",
       "         [0.7961, 0.8118, 0.8353,  ..., 0.1333, 0.0902, 0.0627],\n",
       "         [0.7843, 0.8000, 0.8196,  ..., 0.0980, 0.0588, 0.0431]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_db = CustomImageDataset(\"images/SFU\", \"dry\", preprocess)\n",
    "dataset_q = CustomImageDataset(\"images/SFU\", \"jan\", preprocess)\n",
    "\n",
    "print(\"Dataset Length:\", len(dataset_db))\n",
    "dataset_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 8\n",
    "db_dataloader = DataLoader(dataset_db, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "q_dataloader = DataLoader(dataset_q, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModelCompile(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "    @torch.compile\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\onnx\\_internal\\jit_utils.py:307: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)\n",
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\onnx\\utils.py:702: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\onnx\\utils.py:1209: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ..\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    }
   ],
   "source": [
    "example_input = torch.randn(1, 1, 120, 160)\n",
    "\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    calc,  # model\n",
    "    example_input,  # example input\n",
    "    \"calc_model.onnx\",  # output file name\n",
    "    input_names=[\"input\"],  # input names\n",
    "    output_names=[\"output\"],  # output names\n",
    "    dynamic_axes=dynamic_axes,  # dynamic axes\n",
    ")\n",
    "\n",
    "# Load the ONNX model\n",
    "ort_session = onnxruntime.InferenceSession(\"calc_model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/lrn1/Slice_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 5\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/lrn2/Slice_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 5\n",
      "    }\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'calc_model.onnx'\n",
    "model_quant = 'calc_model_quant_dynamic.onnx'\n",
    "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)\n",
    "\n",
    "# Load the dynamic quantized model\n",
    "ort_session_quant_dynamic = onnxruntime.InferenceSession(\"calc_model_quant_dynamic.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from onnxruntime.tools.symbolic_shape_infer import SymbolicShapeInference\n",
    "\n",
    "from onnxruntime.quantization.shape_inference import quant_pre_process\n",
    "\n",
    "quant_pre_process('calc_model.onnx', 'calc_model_quant_static_prep.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 120, 160])\n",
      "torch.Size([285, 1, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "# calib_ds = db_tensor[:100] # first 100 for calibration - reserve for quantization\n",
    "# val_ds = db_tensor[100:] # last 100 for validation\n",
    "\n",
    "calib_ds = torch.stack([dataset_db[i] for i in range(100)])\n",
    "val_ds = torch.stack([dataset_db[i] for i in range(100, len(dataset_db))])\n",
    "\n",
    "print(calib_ds.shape)\n",
    "print(val_ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxruntime.quantization.calibrate import CalibrationDataReader\n",
    "\n",
    "class QuantizationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, torch_ds, batch_size, input_name):\n",
    "        self.torch_dl = torch.utils.data.DataLoader(torch_ds, batch_size=batch_size, shuffle=False)\n",
    "        self.input_name = input_name\n",
    "        self.datasize = len(self.torch_dl)\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "    def to_numpy(self, pt_tensor):\n",
    "        return pt_tensor.detach().cpu().numpy() if pt_tensor.requires_grad else pt_tensor.cpu().numpy()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.enum_data, None)\n",
    "        if batch is not None:\n",
    "\n",
    "            data = self.to_numpy(batch[0])\n",
    "            data = np.expand_dims(data, axis=0)  # Add a new dimension to the data\n",
    "            \n",
    "            return {self.input_name: data}\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def rewind(self):\n",
    "        self.enum_data = iter(self.torch_dl)\n",
    "\n",
    "qdr = QuantizationDataReader(calib_ds, batch_size=64, input_name=ort_session.get_inputs()[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\n",
      "WARNING:root:failed to infer the type of tensor: . Skip to quantize it. Please check if it is expected.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_static\n",
    "\n",
    "q_static_opts = {\"ActivationSymmetric\":False,\n",
    "                 \"WeightSymmetric\":True}\n",
    "# if torch.cuda.is_available():\n",
    "#     q_static_opts = {\"ActivationSymmetric\":True,\n",
    "#                   \"WeightSymmetric\":True}\n",
    "\n",
    "# q_static_opts = {\"ActivationSymmetric\":False, \"WeightSymmetric\":False}\n",
    "\n",
    "# check layer quantization support\n",
    "\n",
    "quantized_model = quantize_static(model_input='calc_model_quant_static_prep.onnx',\n",
    "                                               model_output='calc_model_quant_static.onnx',\n",
    "                                               calibration_data_reader=qdr,\n",
    "                                               extra_options=q_static_opts)\n",
    "\n",
    "# Load the static quantized model\n",
    "ort_session_quant_static = onnxruntime.InferenceSession('calc_model_quant_static.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization (Quanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n",
      "CalcModel(\n",
      "  (conv1): QConv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): QConv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): QConv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc_quanto = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc_quanto.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc_quanto)\n",
    "\n",
    "quanto.quantize(calc_quanto, weights=quanto.qint8, activations=quanto.qint8) # quantization is in place\n",
    "print(calc_quanto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): CalcModel(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu3): ReLU()\n",
      "    (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "    (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc_compiled = torch.compile(calc, mode='default')\n",
    "\n",
    "print(calc_compiled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 23740, 10636, 11904, 16220, 36212, 28268, 34028, 16280) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m db_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdb_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 23740, 10636, 11904, 16220, 36212, 28268, 34028, 16280) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "calc.eval()\n",
    "\n",
    "# Pass database tensor through the model\n",
    "\n",
    "db_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in db_dataloader:\n",
    "        output = calc(batch)\n",
    "        db_features.append(output)\n",
    "\n",
    "db_features = torch.cat(db_features, axis=0)\n",
    "\n",
    "print(db_features.shape)\n",
    "\n",
    "# Pass query tensor through the model\n",
    "\n",
    "q_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in q_dataloader:\n",
    "        output = calc(batch)\n",
    "        q_features.append(output)\n",
    "\n",
    "q_features = torch.cat(q_features, axis=0)\n",
    "\n",
    "print(q_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model = onnx.load(\"calc_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the tensors to numpy arrays\n",
    "db_matrix = db_tensor.detach().cpu().numpy()\n",
    "q_matrix = q_tensor.detach().cpu().numpy()\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(\"calc_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the input name from the model\n",
    "# input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "# # Ensure the inputs are numpy arrays\n",
    "# db_matrix = np.array(db_matrix)\n",
    "# q_matrix = np.array(q_matrix)\n",
    "\n",
    "# ## Database images\n",
    "\n",
    "# # Create the input dictionary\n",
    "# ort_db_input = {input_name: db_matrix}\n",
    "\n",
    "# # Run the model\n",
    "# ort_db_output = ort_session.run(None, ort_db_input)\n",
    "\n",
    "# # Convert the output to a numpy array and print its shape\n",
    "# ort_db_output = np.array(ort_db_output)\n",
    "# print(ort_db_output.shape)\n",
    "\n",
    "# ## Query images\n",
    "\n",
    "# # Create the input dictionary\n",
    "# ort_q_input = {input_name: q_matrix}\n",
    "\n",
    "# # Run the model\n",
    "# ort_q_output = ort_session.run(None, ort_q_input)\n",
    "\n",
    "# # Convert the output to a numpy array and print its shape\n",
    "# ort_q_output = np.array(ort_q_output)\n",
    "# print(ort_q_output.shape)\n",
    "\n",
    "### USE NUMPY ARRAYS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 17592, 36720, 18068, 31760, 20612, 36396, 35980, 20432) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m input_name \u001b[38;5;241m=\u001b[39m ort_session\u001b[38;5;241m.\u001b[39mget_inputs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m## Database images\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdb_inputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdb_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create the input dictionary\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mort_db_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Run the model\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 17592, 36720, 18068, 31760, 20612, 36396, 35980, 20432) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Get the input name from the model\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "## Database images\n",
    "\n",
    "for db_inputs in db_dataloader:\n",
    "    # Create the input dictionary\n",
    "    ort_db_input = {input_name: db_inputs[0].numpy()}\n",
    "\n",
    "    # Run the model\n",
    "    ort_db_output = ort_session.run(None, ort_db_input)\n",
    "\n",
    "    # Convert the output to a numpy array and print its shape\n",
    "    ort_db_output = np.array(ort_db_output)\n",
    "    print(ort_db_output.shape)\n",
    "\n",
    "## Query images\n",
    "\n",
    "for q_inputs in q_dataloader:\n",
    "    # Create the input dictionary\n",
    "    ort_q_input = {input_name: q_inputs[0].numpy()}\n",
    "\n",
    "    # Run the model\n",
    "    ort_q_output = ort_session.run(None, ort_q_input)\n",
    "\n",
    "    # Convert the output to a numpy array and print its shape\n",
    "    ort_q_output = np.array(ort_q_output)\n",
    "    print(ort_q_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_db_output = np.squeeze(ort_db_output)\n",
    "print(ort_db_output.shape)\n",
    "ort_q_output = np.squeeze(ort_q_output)\n",
    "print(ort_q_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model_quant_dynamic = onnx.load(\"calc_model_quant_dynamic.onnx\")\n",
    "onnx.checker.check_model(onnx_model_quant_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session_quant_dynamic = onnxruntime.InferenceSession(\"calc_model_quant_dynamic.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input name from the model\n",
    "input_name_quant_dynamic = ort_session_quant_dynamic.get_inputs()[0].name\n",
    "\n",
    "# Ensure the inputs are numpy arrays\n",
    "db_matrix = np.array(db_matrix)\n",
    "q_matrix = np.array(q_matrix)\n",
    "\n",
    "## Database images\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_db_input_quant_dynamic = {input_name: db_matrix}\n",
    "\n",
    "# Run the model\n",
    "ort_db_output_quant_dynamic = ort_session_quant_dynamic.run(None, ort_db_input_quant_dynamic)\n",
    "\n",
    "# Convert the output to a numpy array and print its shape\n",
    "ort_db_output_quant_dynamic = np.array(ort_db_output_quant_dynamic)\n",
    "print(ort_db_output_quant_dynamic.shape)\n",
    "\n",
    "## Query images\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_q_input_quant_dynamic = {input_name: q_matrix}\n",
    "\n",
    "# Run the model\n",
    "ort_q_output_quant_dynamic = ort_session_quant_dynamic.run(None, ort_q_input_quant_dynamic)\n",
    "\n",
    "# Convert the output to a numpy array and print its shape\n",
    "ort_q_output_quant_dynamic = np.array(ort_q_output_quant_dynamic)\n",
    "print(ort_q_output_quant_dynamic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Quantized Model (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is a valid ONNX model\n",
    "onnx_model_quant_static = onnx.load(\"calc_model_quant_static.onnx\")\n",
    "onnx.checker.check_model(onnx_model_quant_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session_quant_static = onnxruntime.InferenceSession(\"calc_model_quant_static.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input name from the model\n",
    "input_name_quant_static = ort_session_quant_static.get_inputs()[0].name\n",
    "\n",
    "# Ensure the inputs are numpy arrays\n",
    "db_matrix = np.array(db_matrix)\n",
    "q_matrix = np.array(q_matrix)\n",
    "\n",
    "## Database images\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_db_input_quant_static = {input_name: db_matrix}\n",
    "\n",
    "# Run the model\n",
    "ort_db_output_quant_static = ort_session_quant_static.run(None, ort_db_input_quant_static)\n",
    "\n",
    "# Convert the output to a numpy array and print its shape\n",
    "ort_db_output_quant_static = np.array(ort_db_output_quant_static)\n",
    "print(ort_db_output_quant_static.shape)\n",
    "\n",
    "## Query images\n",
    "\n",
    "# Create the input dictionary\n",
    "ort_q_input_quant_static = {input_name: q_matrix}\n",
    "\n",
    "# Run the model\n",
    "ort_q_output_quant_static = ort_session_quant_static.run(None, ort_q_input_quant_static)\n",
    "\n",
    "# Convert the output to a numpy array and print its shape\n",
    "ort_q_output_quant_static = np.array(ort_q_output_quant_static)\n",
    "print(ort_q_output_quant_static.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization (Quanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 29648, 35532, 17200, 15224, 18800, 18488, 32636, 27824) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m db_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdb_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalc_quanto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Irfan Q\\miniconda3\\envs\\test\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 29648, 35532, 17200, 15224, 18800, 18488, 32636, 27824) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "calc_quanto.eval()\n",
    "\n",
    "# Pass database tensor through the model\n",
    "\n",
    "db_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in db_dataloader:\n",
    "        output = calc_quanto(batch)\n",
    "        db_features.append(output)\n",
    "\n",
    "db_features = torch.cat(db_features, axis=0)\n",
    "\n",
    "print(db_features.shape)\n",
    "\n",
    "# Pass query tensor through the model\n",
    "\n",
    "q_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in q_dataloader:\n",
    "        output = calc_quanto(batch)\n",
    "        q_features.append(output)\n",
    "\n",
    "q_features = torch.cat(q_features, axis=0)\n",
    "\n",
    "print(q_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_compiled.eval()\n",
    "\n",
    "# Pass database tensor through the model\n",
    "\n",
    "db_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in db_dataloader:\n",
    "        output = calc_compiled(batch)\n",
    "        db_features.append(output)\n",
    "\n",
    "db_features = torch.cat(db_features, axis=0)\n",
    "\n",
    "print(db_features.shape)\n",
    "\n",
    "# Pass query tensor through the model\n",
    "\n",
    "q_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in q_dataloader:\n",
    "        output = calc_compiled(batch)\n",
    "        q_features.append(output)\n",
    "\n",
    "q_features = torch.cat(q_features, axis=0)\n",
    "\n",
    "print(q_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing database dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass the dataset through the model\n",
    "    with torch.no_grad():\n",
    "        db_features = []\n",
    "        for batch in db_dataloader:\n",
    "            output = calc(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing query dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in q_dataloader:\n",
    "            output = calc(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing database dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass the dataset through the model\n",
    "    with torch.no_grad():\n",
    "        db_features = []\n",
    "        for batch in db_dataloader:\n",
    "            output = calc_compiled(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing query dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in q_dataloader:\n",
    "            output = calc_compiled(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vprtutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
