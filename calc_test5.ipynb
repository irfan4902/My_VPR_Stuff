{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Irfan Q\\miniconda3\\envs\\bruh\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import quanto\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "from datasets import dataset_utils\n",
    "from matching import matching\n",
    "from evaluation.metrics import createPR, recallAt100precision, recallAtK\n",
    "from datasets.load_dataset import GardensPointDataset, SFUDataset, StLuciaDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_FILE = \"calc.caffemodel.pt\"\n",
    "ITERATIONS = 100 # for testing average duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToYUVandEqualizeHist:\n",
    "    def __call__(self, img):\n",
    "        img_yuv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img_rgb = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        return Image.fromarray(img_rgb)\n",
    "\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        ConvertToYUVandEqualizeHist(),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((120, 160), interpolation=Image.BICUBIC),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, name, folder, transform=None):\n",
    "        \n",
    "        self.name = os.path.basename(name)\n",
    "        self.folder = os.path.join(name, folder)\n",
    "        self.image_paths = dataset_utils.read_images_paths(self.folder, get_abs_path=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        image_path = self.image_paths[index]\n",
    "        img = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length: 385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\Irfan Q\\AppData\\Local\\Temp\\ipykernel_23008\\1463469256.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  dataset_db = CustomImageDataset(\"images\\SFU\", \"dry\", preprocess)\n",
      "C:\\Users\\Irfan Q\\AppData\\Local\\Temp\\ipykernel_23008\\1463469256.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  dataset_q = CustomImageDataset(\"images\\SFU\", \"jan\", preprocess)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3098, 0.4431, 0.6235,  ..., 0.0314, 0.0196, 0.0196],\n",
       "         [0.1882, 0.4471, 0.7020,  ..., 0.0471, 0.0353, 0.0353],\n",
       "         [0.1412, 0.4392, 0.6510,  ..., 0.0431, 0.0314, 0.0353],\n",
       "         ...,\n",
       "         [0.7882, 0.8157, 0.8314,  ..., 0.1529, 0.1176, 0.0824],\n",
       "         [0.7961, 0.8118, 0.8353,  ..., 0.1333, 0.0902, 0.0627],\n",
       "         [0.7843, 0.8000, 0.8196,  ..., 0.0980, 0.0588, 0.0431]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_db = CustomImageDataset(\"images\\SFU\", \"dry\", preprocess)\n",
    "dataset_q = CustomImageDataset(\"images\\SFU\", \"jan\", preprocess)\n",
    "\n",
    "print(\"Dataset Length:\", len(dataset_db))\n",
    "dataset_db[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_workers = 0\n",
    "db_dataloader = DataLoader(dataset_db, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "q_dataloader = DataLoader(dataset_q, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = (1, 120, 160)\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(5, 5), stride=2, padding=4)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(4, 4), stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "        self.conv3 = nn.Conv2d(128, 4, kernel_size=(3, 3), stride=1, padding=0)\n",
    "        self.relu3 = nn.ReLU(inplace=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(3, 3), stride=2)\n",
    "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn1(x)\n",
    "\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.lrn2(x)\n",
    "\n",
    "        x = self.relu3(self.conv3(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalcModel(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
      "  (relu1): ReLU()\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(128, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=(3, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (lrn1): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "  (lrn2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "calc = CalcModel()\n",
    "\n",
    "# Load the model weights\n",
    "state_dict = torch.load(WEIGHTS_FILE)\n",
    "my_new_state_dict = {}\n",
    "my_layers = list(calc.state_dict().keys())\n",
    "for layer in my_layers:\n",
    "    my_new_state_dict[layer] = state_dict[layer]\n",
    "calc.load_state_dict(my_new_state_dict)\n",
    "\n",
    "print(calc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([385, 936])\n",
      "torch.Size([385, 936])\n"
     ]
    }
   ],
   "source": [
    "calc.eval()\n",
    "\n",
    "# Pass database tensor through the model\n",
    "\n",
    "db_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in db_dataloader:\n",
    "        output = calc(batch)\n",
    "        db_features.append(output)\n",
    "\n",
    "db_features = torch.cat(db_features, axis=0)\n",
    "\n",
    "print(db_features.shape)\n",
    "\n",
    "# Pass query tensor through the model\n",
    "\n",
    "q_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in q_dataloader:\n",
    "        output = calc(batch)\n",
    "        q_features.append(output)\n",
    "\n",
    "q_features = torch.cat(q_features, axis=0)\n",
    "\n",
    "print(q_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 100/100 [04:08<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 2.4831705689430237 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing database dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass the dataset through the model\n",
    "    with torch.no_grad():\n",
    "        db_features = []\n",
    "        for batch in db_dataloader:\n",
    "            output = calc(batch)\n",
    "            db_features.append(output)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query dataset: 100%|██████████| 100/100 [04:31<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time: 2.7157634329795837 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "times = [] # Initialize a list to store the time for each pass\n",
    "\n",
    "for _ in tqdm(range(ITERATIONS), desc=\"Processing query dataset\"):\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in q_dataloader:\n",
    "            output = calc(batch)\n",
    "\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "average_time = sum(times) / len(times) # Calculate the average time\n",
    "\n",
    "print(f'Average time: {average_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vprtutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
